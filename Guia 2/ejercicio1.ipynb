{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='text-align: justify;'>\n",
    "<b>Ejercicio 1:</b> Implemente el algoritmo de retropropagación para un perceptrón multicapa de forma que se pueda elegir libremente la cantidad de capas de la red y de neuronas en cada capa. Pruébelo entrenando una red de estructura apropiada para resolver el problema XOR, con sus particiones de entrenamiento y prueba correspondientes (datos de la Guía de Trabajos Prácticos 1).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Librerías</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 1:** Inicialización\n",
    "Determino la estructura de mi red neuronal: el número de capas y neuronas para cada capa. En la variable *cant_entradas*, el primer elemento son las entradas x1,x2,... del archivo, mientras que los próximos elementos me determinan la cantidad de neuronas por capa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_entradas = np.array([2,3,2,1]) # Variable a cambiar según mi red neuronal\n",
    "\n",
    "cant_capas = len(cant_entradas) - 1\n",
    "cant_salidas = cant_entradas[cant_capas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levantamos los datos del archivo .csv, separando en un vector para las entradas y otro para las salidas esperadas. En este caso, entrenamos y probamos el algoritmo con el problema XOR, para lo cual usaremos una red de dos capas y dos entradas x_i. La capa de entrada tendrá 2 neuronas y la capa de salida tendrá 1 neurona.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = np.loadtxt('./data/XOR_trn.csv',delimiter=',')\n",
    "\n",
    "yd = []                         # Salida esperadas\n",
    "for i in range(len(trn)):\n",
    "    fila = trn[i]\n",
    "    cant_e = cant_entradas[0]   # Cantidad de entradas\n",
    "    yd.append(fila[cant_e])\n",
    "    aux = [-1]                  # Añado entrada -1 correspondiente al umbral/sesgo\n",
    "    for j in range(cant_e):\n",
    "        aux.append(fila[j])\n",
    "    trn[i] = aux                # Vector de entradas por patrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializo al azar las matrices de pesos de cada capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.0224112 , -0.20713099,  0.17189526],\n",
      "       [ 0.06439677, -0.32651322, -0.43457923],\n",
      "       [ 0.43931288, -0.08240215,  0.03705989]]), array([[-0.46001166,  0.14929832, -0.18748111,  0.01942142],\n",
      "       [ 0.38082222,  0.19484938,  0.19490848,  0.00917571]]), array([[-0.45881635, -0.31778581, -0.49562906]])]\n"
     ]
    }
   ],
   "source": [
    "# Inicializo la matriz de pesos para cada una de las capas.\n",
    "w = []\n",
    "for i in range(len(cant_entradas)-1):\n",
    "    w_aux = np.random.rand(cant_entradas[i+1],cant_entradas[i]+1)-0.5\n",
    "    w.append(w_aux)     # Añado al vector de matrices de pesos\n",
    "\n",
    "# Estructura de la matriz:\n",
    "print(w)\n",
    "# El elemento w_ij = w[i][j] de la matriz me da los pesos correspondientes a la neurona j de la capa i. \n",
    "# El elemento w_ij[k] me da el peso asociado a la entrada k de la neurona j de la capa i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 2:** Entrenamiento\n",
    "Continuando con el algoritmo, realizamos los pasos de propagación hacia adelante, propagación hacia atrás y adaptación de los pesos en distintas épocas para todas las capas de nuestra red neuronal. Realizamos una pasada de aprendizaje y otra de validación para evaluar el desempeño del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizó el entrenamiento en la época  29  con  0 / 2000  errores\n"
     ]
    }
   ],
   "source": [
    "# DATOS PARA EL ALGORITMO:\n",
    "epoca = 0               # Contador para época actual\n",
    "epoca_max = 50          # Máximo de iteraciones\n",
    "mu = 0.01               # Velocidad de aprendizaje\n",
    "b = 1                   # Constante b para sismóidea\n",
    "perc_error_max = 0.05   # Porcentaje máximo de error\n",
    "errores_por_epoca = []\n",
    "mse_por_epoca = []\n",
    "\n",
    "# TODO: Agregar gráficas dinámicas\n",
    "\n",
    "while (epoca < epoca_max):  \n",
    "    \n",
    "    #--------------------------------#\n",
    "    #--------- Aprendizaje ----------#\n",
    "    #--------------------------------#\n",
    "\n",
    "    for patron in range(len(trn)):\n",
    "\n",
    "        # PROPAGACIÓN HACIA ADELANTE: Obtengo la salida de las capas y las propago como entradas de las próximas\n",
    "        entradas = trn[patron]          # La primera capa tiene las entradas en el archivo .csv\n",
    "        for i in range(cant_capas):\n",
    "            v = w[i]@entradas                  # Producto interno de pesos y entradas\n",
    "            y[i] = 2/(1+np.exp(-b*v))-1        # Salida con función de activación\n",
    "            entradas = np.hstack((-1,y[i]))    # Entrada de la próxima capa es la salida de esta capa\n",
    "        \n",
    "        # PROPAGACIÓN HACIA ATRÁS: Obtengo el delta de la capa de salida y lo propago a las capas anteriores\n",
    "        error = yd[patron] - y[-1]                    \n",
    "        delta[-1]=error*(1/2)*(1+y[-1])*(1-y[-1])       # Con el error, obtengo el delta de la capa de salida\n",
    "        for i in range(cant_capas-1,0,-1):\n",
    "            w_i = w[i][:,1:].T                          # No tomo el peso w0 (umbral) porque no tiene delta para propagar\n",
    "            d = np.dot(w_i,delta[i])\n",
    "            delta[i-1] = d*(1/2)*(1+y[i-1])*(1-y[i-1])  # Con los pesos de la capa i obtenemos el delta de la capa i-1\n",
    "        \n",
    "        # ACTUALIZAR LOS PESOS: Ajusto los pesos con la velocidad de aprendizaje, la entrada y su delta.\n",
    "        entradas = trn[patron]          # La primera capa tiene las entradas en el archivo .csv\n",
    "        for i in range(cant_capas):\n",
    "            delta_peso = mu*(np.outer(delta[i],entradas))\n",
    "            w[i] += delta_peso\n",
    "            entradas = np.hstack((-1,y[i]))    # Entrada para próxima capa es la salida de esta\n",
    "        \n",
    "    #--------------------------------#\n",
    "    #---------- Evaluación ----------#\n",
    "    #--------------------------------#\n",
    "    cont_errores = 0    # Contador de errores\n",
    "    cont_mse = 0        # Contador para error cuadrático medio\n",
    "\n",
    "    for patron in range(len(trn)): \n",
    "\n",
    "        # PROPAGACIÓN HACIA ADELANTE: Obtengo la salida de las capas y las propago como entradas de las próximas\n",
    "        entradas = trn[patron]          # La primera capa tiene las entradas en el archivo .csv\n",
    "        for i in range(cant_capas):\n",
    "            v = w[i]@entradas                  # Producto interno de pesos y entradas\n",
    "            y[i] = 2/(1+np.exp(-b*v)) - 1      # Salida con función de activación\n",
    "            entradas = np.hstack((-1,y[i]))    # Entrada de la próxima capa es la salida de esta capa\n",
    "\n",
    "        # CODIFICACIÓN: Función signo\n",
    "        if (y[-1] < 0): yc = -1\n",
    "        else: yc = 1\n",
    "\n",
    "        # Actualizo contadores de error:\n",
    "        if(yd[patron] != yc): cont_errores += 1\n",
    "        cont_mse += np.sum(np.square(yd[patron]-yc)) \n",
    "\n",
    "    # Actualizo arrays para grafica de error:\n",
    "    mse = cont_mse/len(trn)\n",
    "    mse_por_epoca.append(mse)\n",
    "    errores_por_epoca.append(cont_errores)\n",
    "    # Porcentaje de error para criterio de parada:\n",
    "    perc_error = cont_errores*100/len(trn)\n",
    "    if(perc_error < perc_error_max): break\n",
    "\n",
    "    epoca += 1\n",
    "\n",
    "print('Finalizó el entrenamiento en la época ',epoca,' con ',cont_errores,'/',len(trn),' errores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Paso 3:** Prueba\n",
    "Una vez obtenidos los pesos mediante el entrenamiento, pasamos otro dataset por la red neuronal para probarla. Comenzamos levantando el archivo .csv de la misma forma que para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = np.loadtxt('./data/XOR_tst.csv',delimiter=',')\n",
    "\n",
    "yd = []                         # Salidas esperadas\n",
    "for i in range(len(tst)):\n",
    "    fila = tst[i]\n",
    "    cant_e = cant_entradas[0]   # Cantidad de entradas\n",
    "    yd.append(fila[cant_e])     \n",
    "    aux = [-1]                  # Añado entrada -1 correspondiente al umbral/sesgo\n",
    "    for j in range(cant_e):\n",
    "        aux.append(fila[j])\n",
    "    tst[i] = aux                # Vector de entradas por patrón"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la propagación hacia adelante, manteniendo un contador de errores para determinar la eficiencia del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizó la prueba con  0 / 200  errores.\n"
     ]
    }
   ],
   "source": [
    "y = np.empty(cant_capas,dtype=object)   # Vector de salidas\n",
    "cont_errores = 0                        # Contador de errores\n",
    "\n",
    "for patron in range(len(tst)): \n",
    "    entradas = tst[patron]\n",
    "    for i in range(cant_capas):\n",
    "        v = w[i]@entradas                   # Producto interno de pesos y entradas\n",
    "        y[i] = 2/(1+np.exp(-b*v)) - 1       # Salida con función de activación\n",
    "        entradas = np.hstack((-1,y[i]))     # La entrada de la próxima capa es la salida de la actual.\n",
    "\n",
    "    if (y[-1] < 0): yc = -1\n",
    "    else: yc = 1\n",
    "    if(yd[patron] != yc): cont_errores += 1\n",
    "\n",
    "print('Finalizó la prueba con ',cont_errores,'/',len(tst),' errores.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
