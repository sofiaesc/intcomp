{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** Utilizando las funciones provistas por Scikit-learn, implememente los métodos de ensambles de clasificadores Bagging y AdaBoost. Compare el desempeño de estos modelos empleando 5 particiones con el conjunto de datos Wine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate                   # Para generar tablas\n",
    "\n",
    "from sklearn import datasets                    # Módulo para levantar los datos\n",
    "from sklearn.metrics import accuracy_score      # Medida de precisión\n",
    "from sklearn.model_selection import KFold       # Modelo de partición\n",
    "\n",
    "# Clasificadores:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inicialización**\n",
    "Levanto los datos del conjunto Wine con el módulo datasets y, además, genero una función para el KFold de 5 particiones, al cual le voy a pasar los datos de entrada y el clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits,y_digits = datasets.load_wine(return_X_y=True)  \n",
    "datos_tabla = []\n",
    "\n",
    "def generar_kfold(X_digits,y_digits,clf,n_particiones=5):\n",
    "    kf = KFold(n_splits=n_particiones)\n",
    "    ACC = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_digits):\n",
    "        X_train, X_test = X_digits[train_index], X_digits[test_index]\n",
    "        y_train, y_test = y_digits[train_index], y_digits[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)       # Entreno perceptrón con el conjunto de datos obtenido.\n",
    "        y_pred = clf.predict(X_test)    # Obtengo salida con datos de prueba\n",
    "        ACC_aux = accuracy_score(y_test,y_pred)\n",
    "        ACC.append(ACC_aux)\n",
    "\n",
    "    return ACC\n",
    "\n",
    "def medidas(ACC):\n",
    "    # Medidas globales\n",
    "    print('Exactitud media:',np.mean(ACC))\n",
    "    print('Varianza de la exactitud:',np.var(ACC))\n",
    "    # Medidas tabla\n",
    "    table_data = [[x,y] for x, y in zip(range(len(ACC)), ACC)]\n",
    "    headers = ['N° Partición','Precisión']\n",
    "    table = tabulate(table_data, headers, tablefmt='simple_grid',stralign='center',numalign='center')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ensambles de clasificadores**\n",
    "Para ambos casos hago ensambles de árboles de decisión.\n",
    "\n",
    "- **Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.9442857142857143\n",
      "Varianza de la exactitud: 0.0015344923154446976\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       0        │  0.944444   │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.888889   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │      1      │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.971429   │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "base_clf = DecisionTreeClassifier()\n",
    "clf = BaggingClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.836984126984127\n",
      "Varianza de la exactitud: 0.004632048374905514\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       0        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.742857   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.914286   │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "base_clf = DecisionTreeClassifier()\n",
    "clf = AdaBoostClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
