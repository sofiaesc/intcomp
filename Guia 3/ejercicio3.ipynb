{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** Utilizando las funciones provistas por Scikit-learn, implememente los métodos de ensambles de clasificadores Bagging y AdaBoost. Compare el desempeño de estos modelos empleando 5 particiones con el conjunto de datos Wine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tabulate import tabulate                   # Para generar tablas\n",
    "\n",
    "from sklearn import datasets                    # Módulo para levantar los datos\n",
    "from sklearn.metrics import accuracy_score      # Medida de precisión\n",
    "from sklearn.model_selection import KFold       # Modelo de partición\n",
    "\n",
    "# Clasificadores:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inicialización**\n",
    "Levanto los datos del conjunto Wine con el módulo datasets y, además, genero una función *generar_kfold* para el KFold de 5 particiones, al cual le voy a pasar los datos de entrada y el clasificador. La función *medidas* se encarga de tabular los resultados por partición en cuanto a la precisión del ensamble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits,y_digits = datasets.load_wine(return_X_y=True) \n",
    "datos_tabla = []\n",
    "\n",
    "def generar_kfold(X_digits,y_digits,clf,n_particiones=5):\n",
    "    kf = KFold(n_splits=n_particiones)\n",
    "    ACC = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_digits):\n",
    "        X_train, X_test = X_digits[train_index], X_digits[test_index]\n",
    "        y_train, y_test = y_digits[train_index], y_digits[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)       # Entreno perceptrón con el conjunto de datos obtenido.\n",
    "        y_pred = clf.predict(X_test)    # Obtengo salida con datos de prueba\n",
    "        ACC_aux = accuracy_score(y_test,y_pred)\n",
    "        ACC.append(ACC_aux)\n",
    "\n",
    "    return ACC\n",
    "\n",
    "def medidas(ACC):\n",
    "    # Medidas globales\n",
    "    print('Exactitud media:',np.mean(ACC))\n",
    "    print('Varianza de la exactitud:',np.var(ACC))\n",
    "    # Medidas tabla\n",
    "    table_data = [[x,y] for x, y in zip(range(1,len(ACC)+1), ACC)]\n",
    "    headers = ['N° Partición','Precisión']\n",
    "    table = tabulate(table_data, headers, tablefmt='simple_grid',stralign='center',numalign='center')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ensambles de clasificadores**\n",
    "Para ambos casos hago ensambles de árboles de decisión, modificando la profundidad máxima para ver los resultados en cada caso.\n",
    "\n",
    "- **Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.1757142857142857\n",
      "Varianza de la exactitud: 0.058175762156714536\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │      0      │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.222222   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.0277778  │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.628571   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │      0      │\n",
      "└────────────────┴─────────────┘\n",
      "Exactitud media: 0.9155555555555555\n",
      "Varianza de la exactitud: 0.005498765432098762\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.944444   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.972222   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.861111   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │      1      │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │     0.8     │\n",
      "└────────────────┴─────────────┘\n",
      "Exactitud media: 0.8931746031746032\n",
      "Varianza de la exactitud: 0.0036960443436633884\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.944444   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.861111   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.888889   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.971429   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │     0.8     │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Árbol de decisión con profundidad máxima 1\n",
    "base_clf = DecisionTreeClassifier(max_depth=1)\n",
    "clf = BaggingClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['Bagging (Decision Tree: max_depth = 1)',np.mean(ACC),np.var(ACC)])\n",
    "\n",
    "# Árbol de decisión con profundidad máxima 5\n",
    "base_clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf = BaggingClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['Bagging (Decision Tree: max_depth = 5)',np.mean(ACC),np.var(ACC)])\n",
    "\n",
    "# Árbol de decisión con profundidad máxima 10\n",
    "base_clf = DecisionTreeClassifier(max_depth=20)\n",
    "clf = BaggingClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['Bagging (Decision Tree: max_depth = 20)',np.mean(ACC),np.var(ACC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.6636507936507937\n",
      "Varianza de la exactitud: 0.050525170068027224\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.833333   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.222222   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.742857   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │  0.714286   │\n",
      "└────────────────┴─────────────┘\n",
      "Exactitud media: 0.836984126984127\n",
      "Varianza de la exactitud: 0.004632048374905514\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.742857   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │  0.914286   │\n",
      "└────────────────┴─────────────┘\n",
      "Exactitud media: 0.8080952380952381\n",
      "Varianza de la exactitud: 0.005876643990929703\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.833333   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.833333   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.685714   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │  0.771429   │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "base_clf = DecisionTreeClassifier(max_depth=1)\n",
    "clf = AdaBoostClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['AdaBoost (Decision Tree: max_depth = 1)',np.mean(ACC),np.var(ACC)])\n",
    "\n",
    "base_clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf = AdaBoostClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['AdaBoost (Decision Tree: max_depth = 5)',np.mean(ACC),np.var(ACC)])\n",
    "\n",
    "base_clf = DecisionTreeClassifier(max_depth=20)\n",
    "clf = AdaBoostClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['AdaBoost (Decision Tree: max_depth = 20)',np.mean(ACC),np.var(ACC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusiones**\n",
    "Realizamos una tabla que tenga la precisión media y la varianza de precisión para cada ensamble de clasificadores a modo de comparación, y determinamos el de mejor desempeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌──────────────────────────────────────────┬───────────────────┬────────────┐\n",
      "│                 Ensamble                 │  Precisión media  │  Varianza  │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│  Bagging (Decision Tree: max_depth = 1)  │     0.175714      │ 0.0581758  │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│  Bagging (Decision Tree: max_depth = 5)  │     0.915556      │ 0.00549877 │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│ Bagging (Decision Tree: max_depth = 20)  │     0.893175      │ 0.00369604 │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│ AdaBoost (Decision Tree: max_depth = 1)  │     0.663651      │ 0.0505252  │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│ AdaBoost (Decision Tree: max_depth = 5)  │     0.836984      │ 0.00463205 │\n",
      "├──────────────────────────────────────────┼───────────────────┼────────────┤\n",
      "│ AdaBoost (Decision Tree: max_depth = 20) │     0.808095      │ 0.00587664 │\n",
      "└──────────────────────────────────────────┴───────────────────┴────────────┘\n",
      "El ensamble con una media de precisión más alta es \" Bagging (Decision Tree: max_depth = 5) \" con una media de 0.915556\n",
      "El ensamble con una varianza de precisión más baja es \" Bagging (Decision Tree: max_depth = 20) \" con una varianza de 0.003696\n"
     ]
    }
   ],
   "source": [
    "headers = ['Ensamble','Precisión media','Varianza']\n",
    "table = tabulate(datos_tabla, headers, tablefmt='simple_grid',stralign='center',numalign='center')\n",
    "print(table)\n",
    "\n",
    "max_acc = max(datos_tabla, key=lambda x: x[1])\n",
    "print('El ensamble con una media de precisión más alta es \"', max_acc[0],'\" con una media de',round(max_acc[1],6))\n",
    "\n",
    "min_var = min(datos_tabla, key=lambda x: x[2])\n",
    "print('El ensamble con una varianza de precisión más baja es \"',min_var[0],'\" con una varianza de',round(min_var[2],6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
