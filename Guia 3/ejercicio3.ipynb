{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** Utilizando las funciones provistas por Scikit-learn, implememente los métodos de ensambles de clasificadores Bagging y AdaBoost. Compare el desempeño de estos modelos empleando 5 particiones con el conjunto de datos Wine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tabulate import tabulate                   # Para generar tablas\n",
    "\n",
    "from sklearn import datasets                    # Módulo para levantar los datos\n",
    "from sklearn.metrics import accuracy_score      # Medida de precisión\n",
    "from sklearn.model_selection import KFold       # Modelo de partición\n",
    "\n",
    "# Clasificadores:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Inicialización**\n",
    "Levanto los datos del conjunto Wine con el módulo datasets y, además, genero una función para el KFold de 5 particiones, al cual le voy a pasar los datos de entrada y el clasificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_digits,y_digits = datasets.load_wine(return_X_y=True)  \n",
    "datos_tabla = []\n",
    "\n",
    "def generar_kfold(X_digits,y_digits,clf,n_particiones=5):\n",
    "    kf = KFold(n_splits=n_particiones)\n",
    "    ACC = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_digits):\n",
    "        X_train, X_test = X_digits[train_index], X_digits[test_index]\n",
    "        y_train, y_test = y_digits[train_index], y_digits[test_index]\n",
    "\n",
    "        clf.fit(X_train, y_train)       # Entreno perceptrón con el conjunto de datos obtenido.\n",
    "        y_pred = clf.predict(X_test)    # Obtengo salida con datos de prueba\n",
    "        ACC_aux = accuracy_score(y_test,y_pred)\n",
    "        ACC.append(ACC_aux)\n",
    "\n",
    "    return ACC\n",
    "\n",
    "def medidas(ACC):\n",
    "    # Medidas globales\n",
    "    print('Exactitud media:',np.mean(ACC))\n",
    "    print('Varianza de la exactitud:',np.var(ACC))\n",
    "    # Medidas tabla\n",
    "    table_data = [[x,y] for x, y in zip(range(1,len(ACC)+1), ACC)]\n",
    "    headers = ['N° Partición','Precisión']\n",
    "    table = tabulate(table_data, headers, tablefmt='simple_grid',stralign='center',numalign='center')\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ensambles de clasificadores**\n",
    "Para ambos casos hago ensambles de árboles de decisión.\n",
    "\n",
    "- **Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.9103174603174603\n",
      "Varianza de la exactitud: 0.003600403124212648\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.944444   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.833333   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │      1      │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │  0.857143   │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "base_clf = DecisionTreeClassifier()\n",
    "clf = BaggingClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['Bagging',np.mean(ACC),np.var(ACC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud media: 0.8368253968253969\n",
      "Varianza de la exactitud: 0.005676140085663892\n",
      "┌────────────────┬─────────────┐\n",
      "│  N° Partición  │  Precisión  │\n",
      "├────────────────┼─────────────┤\n",
      "│       1        │  0.916667   │\n",
      "├────────────────┼─────────────┤\n",
      "│       2        │  0.805556   │\n",
      "├────────────────┼─────────────┤\n",
      "│       3        │  0.833333   │\n",
      "├────────────────┼─────────────┤\n",
      "│       4        │  0.714286   │\n",
      "├────────────────┼─────────────┤\n",
      "│       5        │  0.914286   │\n",
      "└────────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "base_clf = DecisionTreeClassifier()\n",
    "clf = AdaBoostClassifier(base_clf,n_estimators=100)\n",
    "ACC = generar_kfold(X_digits,y_digits,clf)\n",
    "medidas(ACC)\n",
    "datos_tabla.append(['AdaBoost',np.mean(ACC),np.var(ACC)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Conclusiones**\n",
    "Realizamos una tabla que tenga la precisión media y la varianza de precisión para cada ensamble de clasificadores a modo de comparación, y determinamos el de mejor desempeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌────────────────┬───────────────────┬────────────┐\n",
      "│  Clasificador  │  Precisión media  │  Varianza  │\n",
      "├────────────────┼───────────────────┼────────────┤\n",
      "│    Bagging     │     0.910317      │ 0.0036004  │\n",
      "├────────────────┼───────────────────┼────────────┤\n",
      "│    AdaBoost    │     0.836825      │ 0.00567614 │\n",
      "└────────────────┴───────────────────┴────────────┘\n",
      "El ensamble con una media de precisión más alta es \" Bagging \" con una media de 0.910317\n",
      "El ensamble con una varianza de precisión más baja es \" Bagging \" con una varianza de 0.0036\n"
     ]
    }
   ],
   "source": [
    "headers = ['Ensamble','Precisión media','Varianza']\n",
    "table = tabulate(datos_tabla, headers, tablefmt='simple_grid',stralign='center',numalign='center')\n",
    "print(table)\n",
    "\n",
    "max_acc = max(datos_tabla, key=lambda x: x[1])\n",
    "print('El ensamble con una media de precisión más alta es \"', max_acc[0],'\" con una media de',round(max_acc[1],6))\n",
    "\n",
    "min_var = min(datos_tabla, key=lambda x: x[2])\n",
    "print('El ensamble con una varianza de precisión más baja es \"',min_var[0],'\" con una varianza de',round(min_var[2],6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
